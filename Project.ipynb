{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                              Deep Learning - Final Project\n",
    "\n",
    "###                                  *Trinidad Bosch*\n",
    "\n",
    "###      The Simpsons                         \n",
    "___________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Dataset Analysis and manipulation\n",
    "- drop null values\n",
    "- look data and make decisions in terms of filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains the lines of the 27 first seasons of 'The Simpsons'. It contains 2 columns: character and spoken words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #for data handling\n",
    "import re #for preprocessing\n",
    "import time #to check time of operations\n",
    "import matplotlib.pyplot as mp #for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_character_text</th>\n",
       "      <th>spoken_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>No, actually, it was a little of both. Sometim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Where's Mr. Bergstrom?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>I don't know. Although I'd sure like to talk t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>That life is worth living.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Edna Krabappel-Flanders</td>\n",
       "      <td>The polls will be open from now until the end ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        raw_character_text                                       spoken_words\n",
       "0              Miss Hoover  No, actually, it was a little of both. Sometim...\n",
       "1             Lisa Simpson                             Where's Mr. Bergstrom?\n",
       "2              Miss Hoover  I don't know. Although I'd sure like to talk t...\n",
       "3             Lisa Simpson                         That life is worth living.\n",
       "4  Edna Krabappel-Flanders  The polls will be open from now until the end ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import dataset \n",
    "df = pd.read_csv (r'simpsons_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>No, actually, it was a little of both. Sometim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Where's Mr. Bergstrom?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>I don't know. Although I'd sure like to talk t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>That life is worth living.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Edna Krabappel-Flanders</td>\n",
       "      <td>The polls will be open from now until the end ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 character                                               text\n",
       "0              Miss Hoover  No, actually, it was a little of both. Sometim...\n",
       "1             Lisa Simpson                             Where's Mr. Bergstrom?\n",
       "2              Miss Hoover  I don't know. Although I'd sure like to talk t...\n",
       "3             Lisa Simpson                         That life is worth living.\n",
       "4  Edna Krabappel-Flanders  The polls will be open from now until the end ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Renaming columns for better use\n",
    "df.rename(columns = {'raw_character_text':'character', 'spoken_words':'text'}, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "character    17814\n",
       "text         26459\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if there are null in the data set\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "character    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dropping null values before text preprocessing\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Before doing any preprocessing we wanted to have a look on the most important characters of the serie, therefore decided to  filter the dataset and work with those characters that have more than 500 dialogue lines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Homer Simpson                   27850\n",
       "Marge Simpson                   13172\n",
       "Bart Simpson                    12995\n",
       "Lisa Simpson                    10756\n",
       "C. Montgomery Burns              3077\n",
       "Moe Szyslak                      2808\n",
       "Seymour Skinner                  2385\n",
       "Ned Flanders                     2056\n",
       "Grampa Simpson                   1802\n",
       "Chief Wiggum                     1790\n",
       "Milhouse Van Houten              1750\n",
       "Krusty the Clown                 1699\n",
       "Lenny Leonard                    1144\n",
       "Nelson Muntz                     1143\n",
       "Apu Nahasapeemapetilon            988\n",
       "Waylon Smithers                   960\n",
       "Kent Brockman                     880\n",
       "Carl Carlson                      852\n",
       "Edna Krabappel-Flanders           719\n",
       "Dr. Julius Hibbert                671\n",
       "Selma Bouvier                     566\n",
       "Barney Gumble                     558\n",
       "Rev. Timothy Lovejoy              550\n",
       "Sideshow Bob                      527\n",
       "Gary Chalmers                     516\n",
       "Groundskeeper Willie              496\n",
       "Mayor Joe Quimby                  494\n",
       "Ralph Wiggum                      468\n",
       "Patty Bouvier                     463\n",
       "Comic Book Guy                    462\n",
       "                                ...  \n",
       "Kozlov                              1\n",
       "Various Congregation Members        1\n",
       "SARAH SILVERMAN                     1\n",
       "GOODTIME SLIM                       1\n",
       "Truong/maria                        1\n",
       "Overlord                            1\n",
       "Nabendu                             1\n",
       "Siegfried                           1\n",
       "Blackula                            1\n",
       "Trucker #5                          1\n",
       "IRISH PETE                          1\n",
       "Judge Lovejoy                       1\n",
       "Christians                          1\n",
       "Prescott Butterfat III              1\n",
       "Statue of Liberty                   1\n",
       "St. Donickus                        1\n",
       "Flanders' Inner Child               1\n",
       "SMOTHERS BROTHERS                   1\n",
       "Nuts & Bolts                        1\n",
       "Bratty Teenage Boy #3               1\n",
       "Homer's Mouth                       1\n",
       "Different Man                       1\n",
       "Cartoon Squid                       1\n",
       "David Cohen                         1\n",
       "Admissions Woman                    1\n",
       "Five Of Diamonds                    1\n",
       "Drycleaner Guys                     1\n",
       "Cowboy Zombie                       1\n",
       "News Crew Member #2                 1\n",
       "Sleazy-looking Woman                1\n",
       "Name: character, Length: 6272, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the % count of the dialogues of each character\n",
    "df.character.value_counts(normalize=True)*100\n",
    "df.character.value_counts()\n",
    "#len(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['character'].value_counts()[:20].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50% of the total lines dialogues corresponds to the Simpson family where Homer 20% of the total. To have a more meaningfull analysis we decided to work with those characters where the count of dialogues is above 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a column that stores the count of each character in the data set \n",
    "df['count'] = df.groupby(['character'])['character'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter those characters that have a count of 1000 or more\n",
    "final_df = df.loc[df['count'] >= 1000] \n",
    "#final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "We will work with 84427 dialogues which corresponds to a 64.03 % of the original dataset\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "final_df.character.value_counts()\n",
    "len_ = len(final_df['text'])\n",
    "len_1 = len(df['text'])\n",
    "print('-------')\n",
    "print(f'We will work with {len_} dialogues which corresponds to a {format(((len_/len_1)*100),\".2f\")} % of the original dataset') \n",
    "print('-------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Extracting contextualized Embeddings\n",
    "> Add description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "     |████████████████████████████████| 85 kB 4.6 MB/s             \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting transformers<5.0.0,>=4.6.0\n",
      "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
      "     |████████████████████████████████| 4.0 MB 19.1 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/lib/python3.6/site-packages (from sentence-transformers) (4.45.0)\n",
      "Collecting torch>=1.6.0\n",
      "  Downloading torch-1.10.2-cp36-cp36m-manylinux1_x86_64.whl (881.9 MB)\n",
      "     |█████████████████████▉          | 600.2 MB 120.2 MB/s eta 0:00:03"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     |████████████████████████████████| 881.9 MB 14 kB/s               \n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading torchvision-0.11.2-cp36-cp36m-manylinux1_x86_64.whl (23.3 MB)\n",
      "     |████████████████████████████████| 23.3 MB 20.1 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy in /export/home/trinidad.bosch-achondo/.local/lib/python3.6/site-packages (from sentence-transformers) (1.19.5)\n",
      "Requirement already satisfied: scikit-learn in /usr/lib64/python3.6/site-packages (from sentence-transformers) (0.23.2)\n",
      "Requirement already satisfied: scipy in /usr/lib64/python3.6/site-packages (from sentence-transformers) (1.3.3)\n",
      "Requirement already satisfied: nltk in /export/home/trinidad.bosch-achondo/.local/lib/python3.6/site-packages (from sentence-transformers) (3.6.7)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "     |████████████████████████████████| 1.3 MB 57.7 MB/s            \n",
      "\u001b[?25hCollecting huggingface-hub>=0.4.0\n",
      "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
      "     |████████████████████████████████| 67 kB 8.8 MB/s             \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/lib/python3.6/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.26.0)\n",
      "Requirement already satisfied: pyyaml in /usr/lib64/python3.6/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /export/home/trinidad.bosch-achondo/.local/lib/python3.6/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.7.4.3)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.4.1-py3-none-any.whl (9.9 kB)\n",
      "Requirement already satisfied: importlib-metadata in /usr/lib/python3.6/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.6.3)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/lib/python3.6/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.0)\n",
      "Requirement already satisfied: dataclasses in /usr/lib/python3.6/site-packages (from torch>=1.6.0->sentence-transformers) (0.8)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /export/home/trinidad.bosch-achondo/.local/lib/python3.6/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.6.2)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
      "     |████████████████████████████████| 880 kB 56.6 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "     |████████████████████████████████| 6.6 MB 36.4 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: click in /usr/lib/python3.6/site-packages (from nltk->sentence-transformers) (7.0)\n",
      "Requirement already satisfied: joblib in /usr/lib/python3.6/site-packages (from nltk->sentence-transformers) (0.16.0)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/lib64/python3.6/site-packages (from torchvision->sentence-transformers) (8.3.1)\n",
      "Collecting torch>=1.6.0\n",
      "  Downloading torch-1.10.1-cp36-cp36m-manylinux1_x86_64.whl (881.9 MB)\n",
      "     |██████████████████████          | 608.1 MB 116.3 MB/s eta 0:00:03"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     |████████████████████████████████| 881.9 MB 25 kB/s               \n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/lib/python3.6/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/lib/python3.6/site-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3.6/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/lib/python3.6/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3.6/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3.6/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2021.5.30)\n",
      "Requirement already satisfied: six in /export/home/trinidad.bosch-achondo/.local/lib/python3.6/site-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.15.0)\n",
      "Building wheels for collected packages: sentence-transformers, sacremoses\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=e1b8df5573a967f12cb7c0d925a093979c2bedbc6db5d483ffaa92fedc7b3002\n",
      "  Stored in directory: /export/home/trinidad.bosch-achondo/.cache/pip/wheels/c9/90/11/0e58d454669bc8daf94e04a8da9956aa6f78eb10cddb16dd4e\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=1b90de75bfaa86e7c84b6a609ee24bb901b3e30b8ca0e901a9e74ce365fb37e3\n",
      "  Stored in directory: /export/home/trinidad.bosch-achondo/.cache/pip/wheels/4c/64/31/e9900a234b23fb3e9dc565d6114a9d6ff84a72dbdd356502b4\n",
      "Successfully built sentence-transformers sacremoses\n",
      "Installing collected packages: filelock, torch, tokenizers, sacremoses, huggingface-hub, transformers, torchvision, sentencepiece, sentence-transformers\n",
      "\u001b[33m  WARNING: The scripts convert-caffe2-to-onnx, convert-onnx-to-caffe2 and torchrun are installed in '/users/trinidad.bosch-achondo/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script sacremoses is installed in '/users/trinidad.bosch-achondo/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script huggingface-cli is installed in '/users/trinidad.bosch-achondo/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script transformers-cli is installed in '/users/trinidad.bosch-achondo/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed filelock-3.4.1 huggingface-hub-0.4.0 sacremoses-0.0.53 sentence-transformers-2.2.2 sentencepiece-0.1.97 tokenizers-0.12.1 torch-1.10.1 torchvision-0.11.2 transformers-4.18.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans ## for later clustering\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pickle, pathlib, re, os\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 GPU(s) available.\n",
      "Device name: Quadro RTX 5000\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available(): #check if GPU is available      \n",
    "    device = torch.device(\"cuda:1\") #set device, we need this later to push our model and the data to the GPU to perform computations\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased',\n",
    "                                  output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    "                                  ).to(device) #push the model into the gpu.\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get embeddings for all words in sentences\n",
    "def emb_func(sentences):\n",
    "    \n",
    "    # Add the special tokens with encode plus.\n",
    "    encoding = tokenizer.encode_plus(sentences, add_special_tokens = True, truncation=True, padding=True,return_attention_mask= True, return_tensors=\"pt\") \n",
    "\n",
    "    tokens_tensor = encoding[\"input_ids\"] \n",
    "    segments_tensors = encoding[\"attention_mask\"] \n",
    "    segments_ids = encoding[\"token_type_ids\"]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        outputs = model(tokens_tensor.to(device), segments_tensors.to(device)) #fit the vectors into the moedel\n",
    "\n",
    "    hidden_states = outputs[2] #extraction of hidden states\n",
    "    \n",
    "    \n",
    "    del outputs   #free gpu --- freeing GPU we avoid CUDA out of memory problem on the server.\n",
    "    \n",
    "\n",
    "    token_embeddings = torch.stack(hidden_states, dim=0) # torch.Size([13, 1, 73, 768])\n",
    "    \n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=1) #torch.Size([13, 73, 768])\n",
    "    \n",
    "    token_embeddings = token_embeddings.permute(1,0,2) #torch.Size([73, 13, 768])\n",
    "    \n",
    "    #Extracting CLS embedding\n",
    "    cls_emb = token_embeddings[0][-4:].mean(dim=0).detach().cpu().numpy() #Extraction of CLS embeddings\n",
    "\n",
    "    # Alternatively we store the token vectors\n",
    "    sent_token_vecs_avg = []\n",
    "\n",
    "    # For each token in the sentence...\n",
    "    for token in token_embeddings:\n",
    "        tok = token.to(\"cpu\")   #feed into a cpu\n",
    "        token.detach() #deletion of the token in GPU \n",
    "        del token  \n",
    "\n",
    "        # Average last four layers.\n",
    "        sum_vec = torch.mean(tok[-4:], dim=0)\n",
    "    \n",
    "        sent_token_vecs_avg.append(sum_vec)\n",
    "\n",
    "    b_emb = torch.stack(sent_token_vecs_avg, dim=0).mean(dim=0).detach().cpu().numpy() #Extraction of the summed embeddings\n",
    "        \n",
    "    return b_emb, cls_emb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def embedding_fun(text): \n",
    "    \n",
    "    #adding the special [CLS] and [SEP] tokens\n",
    "    marked_text = \"[CLS] \" + text + \" [SEP]\" \n",
    "\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    segments_ids = [1] * len(tokenized_text)\n",
    "\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "    \n",
    "    model = BertModel.from_pretrained('bert-base-uncased',\n",
    "                                  output_hidden_states = True,)\n",
    "    #model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor, segments_tensors)\n",
    "    \n",
    "    hidden_states = outputs[2]\n",
    "    \n",
    "    del outputs #free gpu\n",
    "    \n",
    "    # `hidden_states` has shape [13 x 1 x 22 x 768]\n",
    "    token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "\n",
    "    # Remove dimension 1, the \"batches\"\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "    \n",
    "    token_embeddings = token_embeddings.permute(1,0,2)\n",
    "   \n",
    "    #Extracting CLS embedding\n",
    "    cls_emb = token_embeddings[0][-4:].mean(dim=0).detach().cpu().numpy()\n",
    "\n",
    "    \n",
    "    #GENERATING SENTENCE VECTOR\n",
    "    # extracting layer 12 of the network\n",
    "    token_vecs = hidden_states[-1][0]\n",
    "\n",
    "    # Calculate the average of all 22 token vectors.\n",
    "    sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "    \n",
    "    #print (\"Sentence embedding vector of shape:\", sentence_embedding.size())\n",
    "\n",
    "    return sentence_embedding, cls_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Where's Mr. Bergstrom?\", 'That life is worth living.', 'Victory party under the slide!', 'Mr. Bergstrom! Mr. Bergstrom!', 'Do you know where I could find him?', 'The train, how like him... traditional, yet environmentally sound.', 'I see he touched you, too.', 'Hey, thanks for your vote, man.', \"I didn't vote. Voting's for geeks.\", 'Well, you got that right. Thanks for your vote, girls.']\n",
      "['Lisa Simpson', 'Lisa Simpson', 'Bart Simpson', 'Lisa Simpson', 'Lisa Simpson', 'Lisa Simpson', 'Lisa Simpson', 'Bart Simpson', 'Nelson Muntz', 'Bart Simpson']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_list = final_df.text.values.tolist()\n",
    "labels_list = final_df.character.values.tolist()\n",
    "print(text_list[:10])\n",
    "print(labels_list[:10])\n",
    "type(text_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tqdm in /usr/lib/python3.6/site-packages (4.45.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating sentence embeddings: 100%|██████████| 84427/84427 [16:21<00:00, 86.01it/s] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "avg_embeddings = []\n",
    "cls_embeddings = []\n",
    "\n",
    "for idx in tqdm(range(0, len(text_list)), desc =\"Creating sentence embeddings\"):\n",
    "\n",
    "    b_emb, cls_emb = emb_func(text_list[idx])\n",
    "    avg_embeddings.append(b_emb)\n",
    "    cls_embeddings.append(cls_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84427"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(avg_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#avg_embeddings\n",
    "#len(avg_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Saving Embeddings\n",
    "with open('avg_embeddings.pkl', 'wb') as handle:\n",
    "    pickle.dump(avg_embeddings, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('cls_embeddings.pkl', 'wb') as handle:\n",
    "    pickle.dump(cls_embeddings, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Embeddings\n",
    "with open('avg_embeddings.pkl', 'rb') as handle:\n",
    "    avg_embeddings = pickle.load(handle)\n",
    "\n",
    "with open('cls_embeddings.pkl', 'rb') as handle:\n",
    "    cls_embeddings = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Multi-class classification\n",
    "\n",
    "As our aim is to predict the character of a sentence, our task is a Multi-class classification one where we will train a model with labeled data (name of characters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification with averaged embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(avg_embeddings)\n",
    "#avg_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arrange indices \n",
    "indices = np.arange(np.array(avg_embeddings).shape[0])\n",
    "np.random.shuffle(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#avg_embeddings = [t.detach().numpy() for t in avg_embeddings]\n",
    "avg_embeddings, labels = np.array(avg_embeddings), np.array(labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leave this line of code because it works\n",
    "avg_embeddings= np.array(avg_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_embeddings = avg_embeddings[indices]\n",
    "labels_list = labels[indices]\n",
    "labels_list = np.unique(labels_list, return_inverse=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define train and test set\n",
    "training_samples = (max(indices) * 80)//100 #dividing 80%\n",
    "\n",
    "\n",
    "x_train = avg_embeddings[:training_samples]\n",
    "y_train = labels_list[:training_samples]\n",
    "\n",
    "x_test = avg_embeddings[training_samples:]\n",
    "y_test = labels_list[training_samples:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67540, 768)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to categorical labels\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Model - One simple layer\n",
    "\n",
    "- first model with 'adam' function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 7)                 5383      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 14)                112       \n",
      "=================================================================\n",
      "Total params: 5,495\n",
      "Trainable params: 5,495\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/12\n",
      "1689/1689 [==============================] - 2s 989us/step - loss: 2.0624 - acc: 0.3250 - val_loss: 1.9971 - val_acc: 0.3438\n",
      "Epoch 2/12\n",
      "1689/1689 [==============================] - 2s 920us/step - loss: 1.9566 - acc: 0.3565 - val_loss: 1.9477 - val_acc: 0.3656\n",
      "Epoch 3/12\n",
      "1689/1689 [==============================] - 1s 845us/step - loss: 1.9188 - acc: 0.3711 - val_loss: 1.9270 - val_acc: 0.3664\n",
      "Epoch 4/12\n",
      "1689/1689 [==============================] - 1s 845us/step - loss: 1.8967 - acc: 0.3794 - val_loss: 1.9090 - val_acc: 0.3735\n",
      "Epoch 5/12\n",
      "1689/1689 [==============================] - 1s 782us/step - loss: 1.8821 - acc: 0.3840 - val_loss: 1.9066 - val_acc: 0.3761\n",
      "Epoch 6/12\n",
      "1689/1689 [==============================] - 2s 913us/step - loss: 1.8721 - acc: 0.3876 - val_loss: 1.8953 - val_acc: 0.3787\n",
      "Epoch 7/12\n",
      "1689/1689 [==============================] - 2s 902us/step - loss: 1.8629 - acc: 0.3905 - val_loss: 1.8880 - val_acc: 0.3807\n",
      "Epoch 8/12\n",
      "1689/1689 [==============================] - 1s 883us/step - loss: 1.8563 - acc: 0.3921 - val_loss: 1.8859 - val_acc: 0.3793\n",
      "Epoch 9/12\n",
      "1689/1689 [==============================] - 1s 779us/step - loss: 1.8502 - acc: 0.3922 - val_loss: 1.8827 - val_acc: 0.3755\n",
      "Epoch 10/12\n",
      "1689/1689 [==============================] - 1s 767us/step - loss: 1.8447 - acc: 0.3965 - val_loss: 1.8836 - val_acc: 0.3790\n",
      "Epoch 11/12\n",
      "1689/1689 [==============================] - 1s 826us/step - loss: 1.8381 - acc: 0.3972 - val_loss: 1.8752 - val_acc: 0.3833\n",
      "Epoch 12/12\n",
      "1689/1689 [==============================] - 2s 902us/step - loss: 1.8330 - acc: 0.3980 - val_loss: 1.8766 - val_acc: 0.3773\n"
     ]
    }
   ],
   "source": [
    "# Defining the model\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(7, activation='relu', input_shape=(768,)))\n",
    "\n",
    "model.add(layers.Dense(len(set(labels)), activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adamax', loss='categorical_crossentropy', metrics=['acc'])#tried rmsprop, adagrad but adamax seems better\n",
    "model.summary()\n",
    "history = model.fit(x_train, y_train,\n",
    "                            epochs=12,\n",
    "                            batch_size=32,\n",
    "                            validation_split=0.2)\n",
    "model.save_weights('tbbt.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "528/528 [==============================] - 0s 741us/step - loss: 1.8781 - acc: 0.3781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8780611753463745, 0.37810149788856506]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"tbbt.h5\")\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- try a model with 'rmsprop' function "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
